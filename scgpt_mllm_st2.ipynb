{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code implements the Stage 2 Fine-tuning of SC-Phi2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import visdom\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from Baselines.GlobalStateEvaluation.test import show_test_result\n",
    "from data_loader.BatchEnv import BatchSpatialEnv\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Args\n",
    "args = { 'replay_path':  './train_val_test/Protoss_vs_Terran/', # Path to specific race train, val and test files\n",
    "        'exp_name': 'SC:PvP-PvT-922', # Name of the experiment\n",
    "        'race': 'Protoss', # Player race\n",
    "        'enemy_race': 'Terran', # Enemy race\n",
    "        'phase': 'test', # Phase \n",
    "        'gpu_id': 0, # GPU ID\n",
    "        'lr': 5e-5, # Initial learning rate\n",
    "        'n_steps': 4, # No. of frames in each replay\n",
    "        'n_replays': 4, # No. of replays in each batch\n",
    "        'n_epochs': 1, # No. of training epochs\n",
    "        'save_interval': 1e4, # Interval for saving model params    \n",
    "        'seed': 1234, # Seed to make the model more deterministic\n",
    "        'path_to_actions_dict': './actions_protoss.json',  # File to convert action ids to actions  \n",
    "        'save_path': './scgpt-s2/' # Model save path\n",
    "}\n",
    "save_path = os.path.join('./checkpoints/', args['exp_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args['seed'])\n",
    "torch.cuda.manual_seed(args['seed'])\n",
    "np.random.seed(args['seed'])\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define SC-GPT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import SC-GPT specific modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "from peft import get_peft_model, LoraConfig\n",
    "import bitsandbytes as bnb\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to visualize map features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spatial(feats):\n",
    "    feats = feats.cpu().numpy()\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(nrows=5, ncols=13, figsize=(10, 10))\n",
    "    print(ax.shape)\n",
    "    ax = ax.flatten()\n",
    "    for i in range(len(feats)):\n",
    "        ax[i].imshow(feats[i][0])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BatchSpatialEnv()\n",
    "env.init(os.path.join(args['replay_path'], '{}.json'.format(args['phase'])),\n",
    "         './', args['race'], args['enemy_race'], \n",
    "         n_steps=args['n_steps'], seed = args['seed'],\n",
    "         n_replays=args['n_replays'], epochs=args['n_epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "n_frames = 4\n",
    "#n_global_feat = env.n_features_gbl\n",
    "n_scores = 24\n",
    "token_length = 288\n",
    "race = env.race\n",
    "opponenet = env.enemy_race\n",
    "grad_accumulation_steps = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name of the Phi-2 and BLIP-2 ViT from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_llm_id = \"microsoft/phi-2\"\n",
    "base_blip = \"Salesforce/blip2-opt-2.7b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weights from Stage 1 fine-tuned Phi-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = '/data/MSC-master/scgpt-stage2/PvP/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create LoRA config for loading model in LoRA and Quantized format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lora_config(lora_alpha=16, lora_r=8):\n",
    "    lora_config = LoraConfig(\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=0.05,\n",
    "        r=lora_r,\n",
    "        target_modules= ['Wqkv', 'fc1', 'fc2', 'out_proj'], # Target layers where we want to apply LoRA\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\", \n",
    "    )\n",
    "    return lora_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(token_len):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        base_llm_id,\n",
    "        padding_side=\"left\",\n",
    "        add_eos_token=True,\n",
    "        add_bos_token=False,\n",
    "        use_fast=False, \n",
    "        max_length=token_len\n",
    "    )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Phi-2 model from either Huggingface or fine-tuned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm(tokenizer):            \n",
    "    quant_config = BitsAndBytesConfig(load_in_8bit=True, \n",
    "                                        bnb_8bit_compute_dtype=torch.bfloat16, \n",
    "                                        bnb_8bit_use_double_quant=False)\n",
    "    model = AutoModelForCausalLM.from_pretrained(base_llm_id, \n",
    "                                                trust_remote_code=True, \n",
    "                                                quantization_config=quant_config,\n",
    "                                                low_cpu_mem_usage=True,\n",
    "                                                flash_attn = True,\n",
    "                                                flash_rotary = True,\n",
    "                                                fused_dense = True,\n",
    "                                                device_map='auto',\n",
    "                                                revision = 'refs/pr/23')\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.resize_token_embeddings(len(tokenizer)) \n",
    "                                                         \n",
    "    lora_alpha = 192\n",
    "    lora_r = 96\n",
    "    lora_config = create_lora_config(lora_alpha, lora_r)\n",
    "    model = get_peft_model(model, lora_config)    \n",
    "    print(type(model))\n",
    "    print(model.print_trainable_parameters())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a saved tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_tokenizer():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(peft_model)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from the disk using PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "def load_saved_llm(tokenizer):            \n",
    "    quant_config = BitsAndBytesConfig(load_in_8bit=True, \n",
    "                                        bnb_8bit_compute_dtype=torch.bfloat16, \n",
    "                                        bnb_8bit_use_double_quant=False)\n",
    "    model = AutoModelForCausalLM.from_pretrained(base_llm_id, \n",
    "                                                trust_remote_code=True, \n",
    "                                                quantization_config=quant_config,\n",
    "                                                low_cpu_mem_usage=True,\n",
    "                                                flash_attn = True,\n",
    "                                                flash_rotary = True,\n",
    "                                                fused_dense = True,\n",
    "                                                device_map='auto',\n",
    "                                                revision = 'refs/pr/23')\n",
    "\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.resize_token_embeddings(len(tokenizer)) \n",
    "    print(type(model))  \n",
    "    model = PeftModel.from_pretrained(model, peft_model, is_trainable=True)#, quantization_config=quant_config)\n",
    "    print(type(model))\n",
    "    #model = model.merge_and_unload()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load BLIP-2 ViT and its tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visual_encoder():\n",
    "    model = Blip2ForConditionalGeneration.from_pretrained(base_blip, \n",
    "                                        trust_remote_code=True,                                          \n",
    "                                        load_in_8bit=True,\n",
    "                                        low_cpu_mem_usage=True)\n",
    "    return model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blip_processor():\n",
    "    processor = Blip2Processor.from_pretrained(pretrained_model_name_or_path=base_blip, do_rescale=False)\n",
    "    return processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the given prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_prompt(text, tokenizer = None, token_length=100):\n",
    "    result = tokenizer(\n",
    "        text=text,\n",
    "        truncation=True,\n",
    "        max_length=token_length,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \"\"\" if self_supervised:\n",
    "        result['labels'] = result['input_ids'].copy() \"\"\"\n",
    "    return result['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_tokenize_prompt(text, tokenizer = None, token_length=100):\n",
    "    return tokenizer(text, return_tensors='pt').to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need Data Collator to create a batch of prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collator(tokenizer):\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False,  # Set to False for causal language modeling\n",
    "        mlm_probability=0.15  # Probability of masking tokens\n",
    "    )\n",
    "    return data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use global features, ground-truth actions and reward to create a dynamic prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt2(score, vis_text, gt_actions, reward):\n",
    "    score = score.cpu().detach().numpy().tolist()\n",
    "    for i, s in enumerate(score):\n",
    "        if i < 11:\n",
    "            if s >= 0 and s <= 0.2:\n",
    "                score[i] = 'low'\n",
    "            elif s > 0.2 and s <= 0.7:\n",
    "                score[i] = 'medium'\n",
    "            elif s > 0.7:\n",
    "                score[i] = 'high'\n",
    "        else:\n",
    "            if i == 19 or i == 23:\n",
    "                if s >= 0 and s <= 2000:\n",
    "                    score[i] = 'low'\n",
    "                elif s > 2000 and s <= 8000:\n",
    "                    score[i] = 'medium'\n",
    "                elif s > 8000:\n",
    "                    score[i] = 'high'\n",
    "            if i == 18 or i == 22:\n",
    "                if s >= 0 and s <= 10000:\n",
    "                    score[i] = 'low'\n",
    "                elif s > 10000 and s <= 30000:\n",
    "                    score[i] = 'medium'\n",
    "                elif s > 30000:\n",
    "                    score[i] = 'high'\n",
    "            if i == 15:\n",
    "                if s >= 0 and s <= 0.25:\n",
    "                    score[i] = 'early'\n",
    "                elif s > 0.25 and s <= 0.6:\n",
    "                    score[i] = 'mid'\n",
    "                elif s > 0.6 and s <= 0.9:\n",
    "                    score[i] = 'late'\n",
    "                elif s> 0.9:\n",
    "                    score[i] = 'end'\n",
    "\n",
    "\n",
    "    prompt = f'''Instruct: As an expert StarCraft II {race} player, playing against the {opponenet}, predict the next 4 actions and also the result of the game, given the following resources:\n",
    "                Game state: {score[15]}, Army Count: {score[8]}, Army Units/Buildings: {vis_text}\n",
    "                Minerals collected: {score[18]}, Minerals used: {score[22]}, Vespene gas collected: {score[19]}, Vespene gas used: {score[23]}\n",
    "                Food used: {score[3]}, Food cap: {score[4]}, Food for Army: {score[5]}, Food for Workers: {score[6]}\n",
    "                Idle Workers: {score[7]}, Warp gates count: {score[9]}, Larva count: {score[10]}.\n",
    "                Output:                \n",
    "                Action 1: {gt_actions[0]}\n",
    "                Action 2: {gt_actions[1]}\n",
    "                Action 3: {gt_actions[2]}\n",
    "                Action 4: {gt_actions[3]}\n",
    "                Result: {reward}'''\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the prompt is ready, we can tokenize it and send it to SLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize2(scores, text_feats, gt_actions, rewards, tokenizer, token_length=100):\n",
    "    \n",
    "    T, B, F = scores.shape\n",
    "    scores = scores.reshape(B, T, F)\n",
    "    gt_actions = gt_actions.reshape(B, T)\n",
    "    rewards = rewards.reshape(B, T, 1)\n",
    "    \n",
    "    \n",
    "    data = {'input_ids': [], 'labels': []}\n",
    "    for score, text_feat, gt_action, reward in zip(scores, text_feats, gt_actions, rewards):\n",
    "        \n",
    "        score = score.flatten()\n",
    "        rew = 'win' if reward[0] == 1 else 'loss'\n",
    "        actions = id_to_actions(gt_action)\n",
    "        text_prompt = prompt2(score, text_feat[0], actions, rew)\n",
    "        \n",
    "        tokens = tokenize_prompt(text_prompt, tokenizer=tokenizer, token_length=token_length)[0]\n",
    "        \n",
    "        data['input_ids'].append(tokens)\n",
    "        data['labels'].append(tokens)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate textual descriptions from map features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_to_text_features(spatial_features, visual_encoder, vit_processor):\n",
    "    \n",
    "    feats = spatial_features.unsqueeze(3)\n",
    "    \n",
    "    feats = torch.cat([feats, feats, feats], dim=3)\n",
    "\n",
    "    feats = feats[:, :, 4:8, :, :, :]\n",
    "    T, B, F, C, H, W = feats.shape\n",
    "    feats = feats.reshape(B, T*F, C, H, W)\n",
    "    feats = torch.mean(feats, dim=1)\n",
    "    \n",
    "    quest = \"Question: How many circles are there in the image? Answer:\"\n",
    "    \n",
    "    text_feat = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i in range(feats.shape[0]):\n",
    "            inputs = vit_processor(feats[i], text=quest, return_tensors=\"pt\")\n",
    "            out = visual_encoder.generate(**inputs, max_new_tokens=40)\n",
    "            text = vit_processor.batch_decode(out, skip_special_tokens=True)[0].strip().replace('circles', 'buildings')        \n",
    "            text = re.search('\\d+ buildings', text)\n",
    "            if text is None:\n",
    "                text_feat.append('0 buildings')\n",
    "            else: \n",
    "                text_feat.append(''.join(text.group(0))) \n",
    "                \n",
    "    return np.array(text_feat).reshape(B, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load race specific ations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_actions():\n",
    "    act_json = open(args['path_to_actions_dict'], mode='r')\n",
    "    actions_dict = json.load(act_json)\n",
    "    return actions_dict\n",
    "actions_dict = load_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(token_len=token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_saved_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = create_collator(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = load_saved_llm(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = create_llm(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_encoder = create_visual_encoder()\n",
    "vit_processor = create_blip_processor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialized Env and SC-GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SC-GPT: Trainable Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = bnb.optim.AdamW8bit(llm.parameters(), lr=args['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimizer from a saved state\n",
    "optimizer.load_state_dict(torch.load('/data/MSC-master/scgpt-s2/optimizer_911573.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the visdom server\n",
    "vis = visdom.Visdom(env=args['exp_name']+'[{}]'.format(args['phase']), port=8097)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model=llm, visual_encoder=visual_encoder, vit_processor=vit_processor, env=env, args=args, tokenizer=tokenizer):\n",
    "    #################################### PLOT ###################################################\n",
    "    STEPS = 10\n",
    "    LAMBDA = 0.99\n",
    "    \n",
    "    \n",
    "    accumulation_steps = 0\n",
    "    \n",
    "    loss_chart = vis.line(X=np.zeros(1), Y=np.zeros(1), opts=dict(title='Training Loss'))\n",
    "    #acc_chart = vis.line(X=np.zeros(1), Y=np.zeros(1), opts=dict(title='Training Accuracy'))\n",
    "    \n",
    "\n",
    "    #################################### TRAIN ######################################################\n",
    "    \n",
    "    gpu_id = args['gpu_id']\n",
    "   \n",
    "    model.train()\n",
    "    visual_encoder.eval()\n",
    "    \n",
    "    epoch = 0\n",
    "    save = args['save_interval']\n",
    "    env_return = env.step(reward=True, action=True)\n",
    "    if env_return is not None:\n",
    "        \n",
    "        (spatial_features, scores, rewards_gt, actions_gt), require_init = env_return\n",
    "\n",
    "    with torch.cuda.device(gpu_id):\n",
    "        \n",
    "        spatial_features = Variable(torch.from_numpy(spatial_features).to(torch.float16), requires_grad=True)\n",
    "        scores = Variable(torch.from_numpy(scores).to(torch.float16), requires_grad=True)\n",
    "        rewards_gt = Variable(torch.from_numpy(rewards_gt).float(), requires_grad=True)\n",
    "        actions_gt = Variable(torch.from_numpy(actions_gt).to(torch.float32).squeeze(), requires_grad=True)\n",
    "        \n",
    "        if gpu_id >= 0:\n",
    "            \n",
    "            spatial_features = spatial_features.cuda()\n",
    "            scores = scores.cuda()\n",
    "            rewards_gt = rewards_gt.cuda()\n",
    "            actions_gt = actions_gt.cuda()\n",
    "\n",
    "    while True:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        vis_text = spatial_to_text_features(spatial_features, visual_encoder, vit_processor)\n",
    "        \n",
    "        data = tokenize2(scores, vis_text, actions_gt, rewards_gt, tokenizer, token_length=288)\n",
    "        \n",
    "        batch_samples_dict = [{'input_ids': input_ids, 'labels': labels} for input_ids, labels in zip(data['input_ids'], data['labels'])]\n",
    "\n",
    "        del data\n",
    "        \n",
    "        batch = data_collator(batch_samples_dict)\n",
    "        \n",
    "        outputs = llm(**batch)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        del batch\n",
    "        loss.backward()        \n",
    "        if accumulation_steps % grad_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            accumulation_steps = 0\n",
    "        \n",
    "        accumulation_steps += 1\n",
    "\n",
    "        if env.step_count() % 30000 == 0:\n",
    "            \n",
    "            for p in optimizer.param_groups:\n",
    "                p['lr'] *= 0.25\n",
    "        if env.step_count() % 1000 == 0:\n",
    "            print(f'epoch: {epoch}, steps: {np.asarray([env.step_count()])}, loss: {loss.item()}') #, acc: {acc}')\n",
    "        ############################ PLOT ##########################################\n",
    "                \n",
    "        vis.line(X=np.asarray([env.step_count()]),\n",
    "                        Y=np.asarray([loss.cpu().detach()]),\n",
    "                        win=loss_chart,\n",
    "                        name='loss',\n",
    "                        update='append')\n",
    "        \"\"\" vis.line(X=np.asarray([env.step_count()]),\n",
    "                        Y=np.asarray([acc]),\n",
    "                        win=acc_chart,\n",
    "                        name='acc',\n",
    "                        update='append') \"\"\"\n",
    "\n",
    "        ####################### NEXT BATCH ###################################\n",
    "        env_return = env.step(reward=True, action=True)\n",
    "        if env_return is not None:\n",
    "            (raw_spatial, raw_scores, raw_rewards, raw_actions), require_init = env_return            \n",
    "            \n",
    "            spatial_features = spatial_features.copy_(torch.from_numpy(raw_spatial).to(torch.float16))\n",
    "            scores = scores.copy_(torch.from_numpy(raw_scores).to(torch.float16))\n",
    "            rewards_gt = rewards_gt.copy_(torch.from_numpy(raw_rewards).float())\n",
    "            actions_gt = actions_gt.copy_(torch.from_numpy(raw_actions).to(torch.int32).squeeze())\n",
    "\n",
    "        if env.step_count() > save or env_return is None:\n",
    "            save = env.step_count() + args['save_interval']\n",
    "            s = str(env.step_count())\n",
    "            torch.save(llm.state_dict(), args['save_path']+'model_subset_2_'+ s +'.pth')\n",
    "            torch.save(optimizer.state_dict(), args['save_path']+'optimizer_' + s + '.pth')\n",
    "        if env_return is None:\n",
    "            env.close()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate prompt for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt(score, vis_text, gt_actions, reward):\n",
    "    score = score.cpu().detach().numpy().tolist()\n",
    "    for i, s in enumerate(score):\n",
    "        if i < 11:\n",
    "            if s >= 0 and s <= 0.2:\n",
    "                score[i] = 'low'\n",
    "            elif s > 0.2 and s <= 0.7:\n",
    "                score[i] = 'medium'\n",
    "            elif s > 0.7:\n",
    "                score[i] = 'high'\n",
    "        else:\n",
    "            if i == 19 or i == 23:\n",
    "                if s >= 0 and s <= 2000:\n",
    "                    score[i] = 'low'\n",
    "                elif s > 2000 and s <= 8000:\n",
    "                    score[i] = 'medium'\n",
    "                elif s > 8000:\n",
    "                    score[i] = 'high'\n",
    "            if i == 18 or i == 22:\n",
    "                if s >= 0 and s <= 10000:\n",
    "                    score[i] = 'low'\n",
    "                elif s > 10000 and s <= 30000:\n",
    "                    score[i] = 'medium'\n",
    "                elif s > 30000:\n",
    "                    score[i] = 'high'\n",
    "            if i == 15:\n",
    "                if s >= 0 and s <= 0.25:\n",
    "                    score[i] = 'early'\n",
    "                elif s > 0.25 and s <= 0.6:\n",
    "                    score[i] = 'mid'\n",
    "                elif s > 0.6 and s <= 0.9:\n",
    "                    score[i] = 'late'\n",
    "                elif s> 0.9:\n",
    "                    score[i] = 'end'\n",
    "\n",
    "\n",
    "    prompt = f'''Instruct: As an expert StarCraft II {race} player, playing against the {opponenet}, predict the next 4 actions and also the result of the game, given the following resources:\n",
    "                Game stage: {score[15]}, Army Count: {score[8]}, Army Units/Buildings: {vis_text}\n",
    "                Minerals collected: {score[18]}, Minerals used: {score[22]}, Vespene gas collected: {score[19]}, Vespene gas used: {score[23]}\n",
    "                Food used: {score[3]}, Food cap: {score[4]}, Food for Army: {score[5]}, Food for Workers: {score[6]}\n",
    "                Idle Workers: {score[7]}, Warp gates count: {score[9]}, Larva count: {score[10]}.\n",
    "                Output:'''\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the testing replays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env2 = BatchSpatialEnv()\n",
    "env2.init('./train_val_test/Terran_vs_Terran/test_subset.json',\n",
    "         './', args['race'], args['enemy_race'], \n",
    "         n_steps=args['n_steps'], seed = args['seed'],\n",
    "         n_replays=1, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup file to save the generated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = open('eval_results_pvp-to-pvt.csv', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model=llm, visual_encoder=visual_encoder, vit_processor=vit_processor, env=env):\n",
    "    gpu_id = args['gpu_id']\n",
    "    model.eval()\n",
    "    visual_encoder.eval()\n",
    "    \n",
    "    \n",
    "    save = args['save_interval']\n",
    "    env_return = env.step(reward=True, action=True)\n",
    "    if env_return is not None:        \n",
    "        (spatial_features, scores, rewards_gt, actions_gt), require_init = env_return\n",
    "    \n",
    "    eval_results.write('Actions_GT \\t Reward \\t Predictions \\n')\n",
    "    \n",
    "    with torch.cuda.device(gpu_id):\n",
    "        \n",
    "        spatial_features = Variable(torch.from_numpy(spatial_features).to(torch.float16), requires_grad=True)\n",
    "        scores = Variable(torch.from_numpy(scores).to(torch.float16), requires_grad=True)\n",
    "        rewards_gt = Variable(torch.from_numpy(rewards_gt).float(), requires_grad=True)\n",
    "        actions_gt = Variable(torch.from_numpy(actions_gt).to(torch.float32).squeeze(), requires_grad=True)\n",
    "        \n",
    "        if gpu_id >= 0:\n",
    "            \n",
    "            spatial_features = spatial_features.cuda()\n",
    "            scores = scores.cuda()\n",
    "            rewards_gt = rewards_gt.cuda()\n",
    "            actions_gt = actions_gt.cuda()\n",
    "    while True:\n",
    "        \n",
    "        vis_text = spatial_to_text_features(spatial_features, visual_encoder, vit_processor)\n",
    "        \n",
    "        prompt, actions, rew = eval_tokenize(scores, vis_text, actions_gt, rewards_gt, tokenizer, token_length=384)\n",
    "        \n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            row = f\"{actions} \\t {rew} \\t '{tokenizer.decode(llm.generate(**inputs, max_new_tokens=70)[0], skip_special_tokens=True)}'\\n\"\n",
    "            \n",
    "            eval_results.write(row)\n",
    "        \n",
    "        env_return = env.step(reward=True, action=True)\n",
    "        if env_return is not None:\n",
    "            (raw_spatial, raw_scores, raw_rewards, raw_actions), require_init = env_return            \n",
    "            spatial_features = spatial_features.copy_(torch.from_numpy(raw_spatial).to(torch.float16))\n",
    "            scores = scores.copy_(torch.from_numpy(raw_scores).to(torch.float16))\n",
    "            rewards_gt = rewards_gt.copy_(torch.from_numpy(raw_rewards).float())\n",
    "            actions_gt = actions_gt.copy_(torch.from_numpy(raw_actions).to(torch.int32).squeeze())\n",
    "\n",
    "        if env_return is None:\n",
    "            env.close()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(llm.state_dict(), args['save_path']+'model.pth')\n",
    "torch.save(optimizer.state_dict(), args['save_path']+'optimizer.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model=llm, visual_encoder=visual_encoder, vit_processor=vit_processor, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model=llm, visual_encoder=visual_encoder, vit_processor=vit_processor, env=env2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './scgpt-stage2'\n",
    "llm.save_pretrained(out_dir)\n",
    "tokenizer.save_pretrained(out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
